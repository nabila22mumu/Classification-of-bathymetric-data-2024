{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def print_file_contents_in_folder(folder_path):\n",
    "    # Check if the folder path exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No files found in '{folder_path}'.\")\n",
    "    else:\n",
    "        print(f\"Files in '{folder_path}':\")\n",
    "        files_read = 0  # Track the number of files successfully read\n",
    "        \n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        contents = file.read()\n",
    "                        print(f\"Contents of '{file_name}':\")\n",
    "                        print(contents)\n",
    "                        files_read += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading '{file_name}': {e}\")\n",
    "            else:\n",
    "                print(f\"'{file_name}' is not a file.\")\n",
    "        \n",
    "        # Print summary of files read\n",
    "        print(f\"Total files read: {files_read}\")\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = 'Text Files/'\n",
    "\n",
    "# Call the function to print file contents in the folder\n",
    "print_file_contents_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def process_files_in_folder(folder_path):\n",
    "    # Check if the folder path exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No files found in '{folder_path}'.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing files in '{folder_path}':\")\n",
    "    \n",
    "    returning_points = []  # List to store returning points for every 10 files\n",
    "    x_cor = []  # List to store x coordinates\n",
    "    y_cor = []  # List to store y coordinates\n",
    "    z_cor = []  # List to store z coordinates\n",
    "    file_count = 0\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            # Initialize variables to store extracted values\n",
    "            sample_length = None\n",
    "            point = None\n",
    "            \n",
    "            # Define a regular expression pattern to match floating-point numbers\n",
    "            pattern = r\"[-+]?\\d*\\.\\d+|\\d+\"\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    file_contents = file.readlines()\n",
    "                    \n",
    "                    # Extract the Point (x, y, z) coordinates from the first line\n",
    "                    point_match = re.findall(pattern, file_contents[0])\n",
    "                    if len(point_match) >= 3:\n",
    "                        x = float(point_match[0])\n",
    "                        y = float(point_match[1])\n",
    "                        z = float(point_match[2])\n",
    "                        \n",
    "                        # Store coordinates in separate lists\n",
    "                        x_cor.append(x)\n",
    "                        y_cor.append(y)\n",
    "                        z_cor.append(z)\n",
    "                    \n",
    "                    # Check if the file has at least 7 lines\n",
    "                    if len(file_contents) >= 7:\n",
    "                        # Extract numeric values from lines 6 and 7 using regular expressions\n",
    "                        sample_length_match = re.findall(pattern, file_contents[5])\n",
    "                        point_match = re.findall(pattern, file_contents[6])\n",
    "                        \n",
    "                        # Convert the matched values to floats\n",
    "                        if sample_length_match:\n",
    "                            sample_length = float(sample_length_match[0])\n",
    "                        if point_match:\n",
    "                            point = float(point_match[0])\n",
    "                            \n",
    "                        # Calculate Returning Point\n",
    "                        if sample_length is not None and point is not None:\n",
    "                            returning_point = point / sample_length\n",
    "                            print(f\"File: {file_name}\")\n",
    "                            print(\"Sample Length:\", sample_length)\n",
    "                            print(\"Point:\", point)\n",
    "                            print(\"Returning Point:\", returning_point)\n",
    "                            \n",
    "                            # Store returning point in the list\n",
    "                            returning_points.append(returning_point)\n",
    "                            \n",
    "                            file_count += 1\n",
    "                            \n",
    "                            # Check if we have processed 10 files\n",
    "                            if file_count % 10 == 0:\n",
    "                                print(f\"Returning Points after {file_count} files:\", returning_points)\n",
    "                                print(f\"x Coordinates after {file_count} files:\", x_cor)\n",
    "                                print(f\"y Coordinates after {file_count} files:\", y_cor)\n",
    "                                print(f\"z Coordinates after {file_count} files:\", z_cor)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing '{file_name}': {e}\")\n",
    "        else:\n",
    "            print(f\"'{file_name}' is not a file.\")\n",
    "    \n",
    "    # Print final returning points and coordinates after processing all files\n",
    "    print(f\"Final Returning Points after processing {file_count} files:\", returning_points)\n",
    "    print(f\"Final x Coordinates after processing {file_count} files:\", x_cor)\n",
    "    print(f\"Final y Coordinates after processing {file_count} files:\", y_cor)\n",
    "    print(f\"Final z Coordinates after processing {file_count} files:\", z_cor)\n",
    "\n",
    "# Call the function to process files in the folder\n",
    "process_files_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a264ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "\n",
    "def process_files_in_folder(folder_path):\n",
    "    # Check if the folder path exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No files found in '{folder_path}'.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing files in '{folder_path}':\")\n",
    "    \n",
    "    returning_points = []  # List to store returning points for every 10 files\n",
    "    file_data = []  # List to store data for table\n",
    "    \n",
    "    file_count = 0\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            # Initialize variables to store extracted values\n",
    "            sample_length = None\n",
    "            point = None\n",
    "            \n",
    "            # Define a regular expression pattern to match floating-point numbers\n",
    "            pattern = r\"[-+]?\\d*\\.\\d+|\\d+\"\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    file_contents = file.readlines()\n",
    "                    \n",
    "                    # Check if the file has at least 7 lines\n",
    "                    if len(file_contents) >= 7:\n",
    "                        # Extract numeric values from lines 6 and 7 using regular expressions\n",
    "                        sample_length_match = re.findall(pattern, file_contents[5])\n",
    "                        point_match = re.findall(pattern, file_contents[6])\n",
    "                        \n",
    "                        # Convert the matched values to floats\n",
    "                        if sample_length_match:\n",
    "                            sample_length = float(sample_length_match[0])\n",
    "                        if point_match:\n",
    "                            point = float(point_match[0])\n",
    "                            \n",
    "                        # Calculate Returning Point\n",
    "                        if sample_length is not None and point is not None:\n",
    "                            returning_point = point / sample_length\n",
    "                            \n",
    "                            # Store data for table\n",
    "                            file_data.append([file_name, sample_length, point, returning_point])\n",
    "                            \n",
    "                            file_count += 1\n",
    "                            \n",
    "                            # Check if we have processed 10 files\n",
    "                            if file_count % 10 == 0:\n",
    "                                print(f\"Returning Points after {file_count} files:\", returning_points)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing '{file_name}': {e}\")\n",
    "        else:\n",
    "            print(f\"'{file_name}' is not a file.\")\n",
    "    \n",
    "    # Print final returning points after processing all files\n",
    "    print(f\"Final Returning Points after processing {file_count} files:\", returning_points)\n",
    "    \n",
    "    # Display data in a table\n",
    "    headers = [\"File Name\", \"Sample Length\", \"Point\", \"Returning Point\"]\n",
    "    print(tabulate(file_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "\n",
    "\n",
    "# Call the function to process files in the folder\n",
    "process_files_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d5c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "def read_file_contents(folder_path):\n",
    "    file_contents_dict = {}\n",
    "    \n",
    "    # List all files in the specified folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    # Read all lines from the file\n",
    "                    file_contents = file.readlines()\n",
    "                    \n",
    "                    # Store file contents in the dictionary\n",
    "                    file_contents_dict[file_name] = file_contents\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file '{file_name}': {e}\")\n",
    "    \n",
    "    return file_contents_dict\n",
    "\n",
    "def plot_channel_1_samples(file_contents_dict):\n",
    "    for file_name, file_contents in file_contents_dict.items():\n",
    "        channel_1_samples = []  # List to store Channel 1 samples for plotting\n",
    "        \n",
    "        # Define a regular expression pattern to match integer values\n",
    "        pattern = r\"\\d+\"\n",
    "        \n",
    "        found_channel_1_samples = False\n",
    "        for line in file_contents:\n",
    "            line = str(line).strip()  # Ensure line is converted to string and stripped\n",
    "            \n",
    "            if found_channel_1_samples and line:\n",
    "                # Extract and convert numeric values from lines after 'Channel 1 samples'\n",
    "                sample_matches = re.findall(pattern, line)\n",
    "                for sample in sample_matches:\n",
    "                    channel_1_samples.append(int(sample))\n",
    "                \n",
    "            if line == 'Channel 1 samples':\n",
    "                found_channel_1_samples = True\n",
    "        \n",
    "        # Plot Channel 1 samples\n",
    "        if channel_1_samples:\n",
    "            plt.figure(figsize=(16, 6))\n",
    "            plt.plot(range(1, len(channel_1_samples) + 1), channel_1_samples)\n",
    "            plt.xlabel('Sample')\n",
    "            plt.ylabel('Value')\n",
    "            plt.title(f'Channel 1 Samples from {file_name}')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# Read file contents from the specified folder\n",
    "file_contents_dict = read_file_contents(folder_path)\n",
    "\n",
    "# Call the function to plot Channel 1 samples for each file\n",
    "plot_channel_1_samples(file_contents_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c82af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_values_from_files(folder_path):\n",
    "    file_value_arrays = {}  # Dictionary to store arrays of values for each file\n",
    "    \n",
    "    # List all files in the specified folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            # Initialize an empty array to store the lines (values) from the file\n",
    "            values_array = []\n",
    "            \n",
    "            try:\n",
    "                # Open the file in read mode\n",
    "                with open(file_path, 'r') as file:\n",
    "                    # Skip the first 11 lines\n",
    "                    for _ in range(11):\n",
    "                        next(file)\n",
    "                    \n",
    "                    # Read the rest of the lines (values) and store them in the array\n",
    "                    for line in file:\n",
    "                        values_array.append(line.strip())\n",
    "                \n",
    "                # Store the values array in the dictionary with file name as the key\n",
    "                file_value_arrays[file_name] = values_array\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file '{file_name}': {e}\")\n",
    "        \n",
    "    return file_value_arrays\n",
    "\n",
    "\n",
    "# Read values from files in the specified folder\n",
    "file_value_arrays = read_values_from_files(folder_path)\n",
    "\n",
    "# Print the arrays with file name as array name and number of values stored\n",
    "for file_name, values_array in file_value_arrays.items():\n",
    "    array_name = file_name.replace('.txt', '_array')  # Generate array name from file name\n",
    "    num_values = len(values_array)  # Get the number of values in the array\n",
    "    print(f\"{array_name}: {values_array} (Number of values: {num_values})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b328841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_values_from_files(folder_path):\n",
    "    file_value_arrays = {}  # Dictionary to store arrays of values for each file\n",
    "    \n",
    "    # List all files in the specified folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            # Initialize an empty array to store the lines (values) from the file\n",
    "            values_array = []\n",
    "            \n",
    "            try:\n",
    "                # Open the file in read mode\n",
    "                with open(file_path, 'r') as file:\n",
    "                    # Skip the first 11 lines\n",
    "                    for _ in range(11):\n",
    "                        next(file)\n",
    "                    \n",
    "                    # Read the rest of the lines (values) and store them in the array\n",
    "                    for line in file:\n",
    "                        values_array.append(line.strip())\n",
    "                \n",
    "                # Store the values array in the dictionary with file name as the key\n",
    "                file_value_arrays[file_name] = values_array\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file '{file_name}': {e}\")\n",
    "        \n",
    "    return file_value_arrays\n",
    "\n",
    "def clean_values(file_value_arrays):\n",
    "    cleaned_value_arrays = {}  # Dictionary to store cleaned arrays of values\n",
    "    \n",
    "    for file_name, values_array in file_value_arrays.items():\n",
    "        # Extract values from index 101 to 400 (inclusive) to clean the data\n",
    "        cleaned_values = values_array[100:400] #changed to 600 from 400\n",
    "        \n",
    "        # Store the cleaned values array in the dictionary with file name as the key\n",
    "        cleaned_value_arrays[file_name] = cleaned_values\n",
    "    \n",
    "    return cleaned_value_arrays\n",
    "\n",
    "\n",
    "\n",
    "# Read values from files in the specified folder\n",
    "file_value_arrays = read_values_from_files(folder_path)\n",
    "\n",
    "# Clean the values arrays by extracting values from index 101 to 400\n",
    "cleaned_value_arrays = clean_values(file_value_arrays)\n",
    "\n",
    "# Print the cleaned arrays with file name as array name and number of values stored\n",
    "for file_name, cleaned_values in cleaned_value_arrays.items():\n",
    "    array_name = file_name.replace('.txt', '_cleaned_array')  # Generate array name from file name\n",
    "    num_values = len(cleaned_values)  # Get the number of cleaned values\n",
    "    print(f\"{array_name}: {cleaned_values} \\n( Number of values: {num_values})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_values_from_files(folder_path):\n",
    "    file_value_arrays = {}  # Dictionary to store arrays of values for each file\n",
    "    \n",
    "    # List all files in the specified folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            # Initialize an empty array to store the lines (values) from the file\n",
    "            values_array = []\n",
    "            \n",
    "            try:\n",
    "                # Open the file in read mode\n",
    "                with open(file_path, 'r') as file:\n",
    "                    # Skip the first 11 lines\n",
    "                    for _ in range(11):\n",
    "                        next(file)\n",
    "                    \n",
    "                    # Read the rest of the lines (values) and store them in the array\n",
    "                    for line in file:\n",
    "                        values_array.append(line.strip())\n",
    "                \n",
    "                # Store the values array in the dictionary with file name as the key\n",
    "                file_value_arrays[file_name] = values_array\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file '{file_name}': {e}\")\n",
    "        \n",
    "    return file_value_arrays\n",
    "\n",
    "def clean_and_generate_table(file_value_arrays):\n",
    "    table_data = {}  # Dictionary to store table data for each file\n",
    "    \n",
    "    for file_name, values_array in file_value_arrays.items():\n",
    "        # Extract values from index 101 to 400 (inclusive) to clean the data\n",
    "        cleaned_values = values_array[100:400] ####\n",
    "        \n",
    "        # Create table rows for the file\n",
    "        table_rows = []\n",
    "        class_label = 0  # Initial class label\n",
    "        \n",
    "        for i, value in enumerate(cleaned_values, start=101):\n",
    "            # Create a row for the table with sample number, value, and class label\n",
    "            table_rows.append([i, value, class_label])\n",
    "        \n",
    "        # Store table rows in the dictionary with file name as the key\n",
    "        table_data[file_name] = table_rows\n",
    "    \n",
    "    return table_data\n",
    "\n",
    "def print_table(table_data):\n",
    "    # Print the table for each file\n",
    "    for file_name, table_rows in table_data.items():\n",
    "        print(f\"Table for {file_name}:\")\n",
    "        print(\"Sample_no\\tSamples\\tClass_Label\")\n",
    "        for row in table_rows:\n",
    "            print(\"\\t\".join(map(str, row)))\n",
    "        print()  # Print a blank line for separation\n",
    "\n",
    "\n",
    "\n",
    "# Read values from files in the specified folder\n",
    "file_value_arrays = read_values_from_files(folder_path)\n",
    "\n",
    "# Clean values and generate table data for each file\n",
    "table_data = clean_and_generate_table(file_value_arrays)\n",
    "\n",
    "# Print tables for each file\n",
    "print_table(table_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a941b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_table_data_types(table_data):\n",
    "    # Iterate over each file's table data\n",
    "    for file_name, table_rows in table_data.items():\n",
    "        print(f\"Table for {file_name}:\")\n",
    "        print(\"Sample_no\\tSamples\\tClass_Label\")\n",
    "        \n",
    "        # Print each row of the table and check data types\n",
    "        for row in table_rows:\n",
    "            sample_no, samples, class_label = row\n",
    "            # Print the row\n",
    "           # print(f\"{sample_no}\\t{samples}\\t{class_label}\")\n",
    "            \n",
    "            # Check data types of elements in the row\n",
    "            print(\"Data Types:\")\n",
    "            print(f\"Sample_no: {type(sample_no)}\")\n",
    "            print(f\"Samples: {type(samples)}\")\n",
    "            print(f\"Class_Label: {type(class_label)}\")\n",
    "            \n",
    "        print()  \n",
    "# Call the function to check data types of elements in each table\n",
    "check_table_data_types(table_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_table_to_integers(table_data):\n",
    "    # Iterate over each file's table data\n",
    "    for file_name, table_rows in table_data.items():\n",
    "        print(f\"Table for {file_name}:\")\n",
    "        print(\"Sample_no\\tSamples\\tClass_Label\")\n",
    "        \n",
    "        # Convert each element in the table_rows list to integer data type\n",
    "        for row in table_rows:\n",
    "            row[0] = int(row[0])  # Convert Sample_no to int\n",
    "            row[1] = int(row[1])  # Convert Samples to int\n",
    "            row[2] = int(row[2])  # Convert Class_Label to int\n",
    "            \n",
    "            # Print the updated row with integer data types\n",
    "            print(f\"{row[0]}\\t{row[1]}\\t{row[2]}\")\n",
    "        \n",
    "        print()  # Print a blank line for separation\n",
    "\n",
    "\n",
    "# Call the function to convert table elements to integers and print updated tables\n",
    "convert_table_to_integers(table_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_table_data_types(table_data):\n",
    "    # Iterate over each file's table data\n",
    "    for file_name, table_rows in table_data.items():\n",
    "        print(f\"Table for {file_name}:\")\n",
    "        print(\"Sample_no\\tSamples\\tClass_Label\")\n",
    "        \n",
    "        # Print each row of the table and check data types\n",
    "        for row in table_rows:\n",
    "            sample_no, samples, class_label = row\n",
    "            # Print the row\n",
    "           # print(f\"{sample_no}\\t{samples}\\t{class_label}\")\n",
    "            \n",
    "            # Check data types of elements in the row\n",
    "            print(\"Data Types:\")\n",
    "            print(f\"Sample_no: {type(sample_no)}\")\n",
    "            print(f\"Samples: {type(samples)}\")\n",
    "            print(f\"Class_Label: {type(class_label)}\")\n",
    "            \n",
    "        print()  \n",
    "\n",
    "check_table_data_types(table_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9537a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_types_table(table_data):\n",
    "    # Iterate over each file's table data\n",
    "    for file_name, table_rows in table_data.items():\n",
    "        print(f\"Data Types Table for {file_name}:\")\n",
    "        print(\"Sample_no\\tSamples\\tClass_Label\")\n",
    "        \n",
    "        # Iterate over each row in the table and print data types\n",
    "        for row in table_rows:\n",
    "            data_types_row = []\n",
    "            for column_value in row:\n",
    "                data_types_row.append(type(column_value).__name__)\n",
    "            \n",
    "            # Print the row of data types\n",
    "            print(\"\\t\".join(data_types_row))\n",
    "        \n",
    "        print()  # Print a blank line after each file's data types table\n",
    "\n",
    "\n",
    "# Call the function to print data types table for each file\n",
    "print_data_types_table(table_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c8491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_with_peaks(table_data):\n",
    "    # Iterate over each file's table data\n",
    "    for file_name, table_rows in table_data.items():\n",
    "        print(f\"Plotting data for {file_name}:\")\n",
    "        \n",
    "        # Extract Sample_no and Samples values from each row\n",
    "        sample_numbers = [row[0] for row in table_rows]\n",
    "        samples = [row[1] for row in table_rows]\n",
    "        \n",
    "        # Find peaks in the samples\n",
    "        peaks, _ = find_peaks(samples, height=0)\n",
    "        \n",
    "        # Plot Sample_no vs Samples\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(sample_numbers, samples, marker='o', linestyle='-', label='Samples')\n",
    "        \n",
    "        # Mark samples with dots\n",
    "        plt.scatter(sample_numbers, samples, color='red', label='Marked Samples')\n",
    "        \n",
    "        # Highlight detected peaks\n",
    "        peak_sample_numbers = [sample_numbers[i] for i in peaks]  # Get sample numbers at peak indices\n",
    "        peak_samples = [samples[i] for i in peaks]  # Get sample values at peak indices\n",
    "        plt.plot(peak_sample_numbers, peak_samples, \"x\", markersize=10, color='orange', label='Detected Peaks')\n",
    "        \n",
    "        plt.title(f'Sample_no vs Samples for {file_name}')\n",
    "        plt.xlabel('Sample_no')\n",
    "        plt.ylabel('Samples')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Call the function to plot data for each file with peaks\n",
    "plot_data_with_peaks(table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_with_top_peaks_and_regions(table_data):\n",
    "    precomputed_peaks = {}\n",
    "    regions_dict = {}\n",
    "\n",
    "    for file_name, table_rows in table_data.items():\n",
    "        print(f\"Processing data for {file_name}:\")\n",
    "\n",
    "        sample_numbers = [row[0] for row in table_rows]\n",
    "        samples = [row[1] for row in table_rows]\n",
    "        \n",
    "        # Dynamically adjust the prominence \n",
    "        dynamic_prominence = max(samples) * 0.1  # 10% of the max sample value\n",
    "        \n",
    "        # Find peaks with adjusted parameters\n",
    "        peaks, _ = find_peaks(samples, height=3000, prominence=dynamic_prominence, distance=1)\n",
    "        \n",
    "        # Fallback if no peaks are found\n",
    "        if len(peaks) == 0:\n",
    "            prominence_threshold = max(samples) * 0.05\n",
    "            peaks, _ = find_peaks(samples, height=1000, prominence=prominence_threshold, distance=1)\n",
    "        \n",
    "        # Debug prints for detected peaks\n",
    "        peak_samples = [samples[i] for i in peaks]\n",
    "        print(f\"Detected Peaks Indices: {peaks}\")\n",
    "        print(f\"Detected Peak Values: {peak_samples}\")\n",
    "        \n",
    "        # Store the peaks for the current file\n",
    "        precomputed_peaks[file_name] = peaks\n",
    "        \n",
    "        # Plot Sample_no vs Samples\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(sample_numbers, samples, marker='o', linestyle='-', label='Samples')\n",
    "        \n",
    "        # Mark all detected peaks\n",
    "        peak_sample_numbers = [sample_numbers[i] for i in peaks]\n",
    "        peak_samples = [samples[i] for i in peaks]\n",
    "        plt.plot(peak_sample_numbers, peak_samples, \"x\", markersize=10, color='black', label='Detected Peaks')\n",
    "        \n",
    "        # List to store marked regions\n",
    "        marked_regions = []\n",
    "        \n",
    "        if len(peaks) > 0:\n",
    "            # Sort peaks by their sample number\n",
    "            sorted_peak_indices = np.argsort(peak_sample_numbers)\n",
    "            sorted_peak_sample_numbers = [peak_sample_numbers[i] for i in sorted_peak_indices]\n",
    "            sorted_peak_samples = [peak_samples[i] for i in sorted_peak_indices]\n",
    "            \n",
    "            # Determine the number of peaks\n",
    "            num_peaks = len(sorted_peak_sample_numbers)\n",
    "            \n",
    "            # Mark regions around each of the peaks\n",
    "            for idx, peak_sample_no in enumerate(sorted_peak_sample_numbers):\n",
    "                peak_index = sample_numbers.index(peak_sample_no)\n",
    "                \n",
    "                # Define the range of indices for the region\n",
    "                if idx == 0:  # For the peak with the smallest sample number\n",
    "                    start_index = max(peak_index - 10, 0)\n",
    "                    end_index = min(peak_index + 6, len(sample_numbers))\n",
    "                else:  # For all other peaks\n",
    "                    start_index = max(peak_index - 5, 0)\n",
    "                    end_index = min(peak_index + 6, len(sample_numbers))\n",
    "                \n",
    "                # Extract sample numbers and values for the region\n",
    "                region_sample_no = sample_numbers[start_index:end_index]\n",
    "                region_values = samples[start_index:end_index]\n",
    "                \n",
    "                # Append sample numbers and values to marked regions list\n",
    "                marked_regions.append((region_sample_no, region_values))\n",
    "                \n",
    "                # Plot the region\n",
    "                plt.plot(region_sample_no, region_values, marker='o', linestyle='-', label=f'Region around {peak_sample_no}')\n",
    "        \n",
    "        plt.title(f'Sample_no vs Samples for {file_name} with Marked Regions')\n",
    "        plt.xlabel('Sample_no')\n",
    "        plt.ylabel('Samples')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        # Sort the marked regions based on sample numbers (ascending order)\n",
    "        marked_regions.sort(key=lambda x: x[0][0])\n",
    "        regions_dict[file_name] = marked_regions\n",
    "        \n",
    "        # Print the sorted sample numbers and values of the marked regions\n",
    "        for idx, (region_sample_no, region_values) in enumerate(marked_regions, start=1):\n",
    "            print(f\"Region {idx} - Sample Numbers:\", region_sample_no)\n",
    "            print(f\"Region {idx} - Sample Values:\", region_values)\n",
    "            print()\n",
    "\n",
    "    return precomputed_peaks, regions_dict\n",
    "\n",
    "# Call the function to plot data for each file with top peaks and marked regions\n",
    "precomputed_peaks, regions_dict = plot_data_with_top_peaks_and_regions(table_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc44a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_sample_numbers_and_regions(table_data, precomputed_peaks):\n",
    "    # Dictionary to store sample numbers and regions for each file\n",
    "    sample_numbers_and_regions = {}\n",
    "\n",
    "    # Iterate over each file's table data\n",
    "    for file_name, table_rows in table_data.items():\n",
    "        print(f\"Processing data for {file_name}:\")\n",
    "\n",
    "        # Extract Sample_no and Samples values from each row\n",
    "        sample_numbers = [row[0] for row in table_rows]\n",
    "        samples = [row[1] for row in table_rows]\n",
    "\n",
    "        # Retrieve precomputed peaks for the current file\n",
    "        if file_name not in precomputed_peaks:\n",
    "            print(f\"No precomputed peaks found for {file_name}\")\n",
    "            continue\n",
    "\n",
    "        peaks = precomputed_peaks[file_name]\n",
    "\n",
    "        # List to store regions for the current file\n",
    "        regions = []\n",
    "\n",
    "        # Get peak sample numbers and sort by sample number\n",
    "        peak_sample_numbers = [sample_numbers[peak] for peak in peaks]\n",
    "        sorted_peak_indices = np.argsort(peak_sample_numbers)\n",
    "        sorted_peak_sample_numbers = [peak_sample_numbers[i] for i in sorted_peak_indices]\n",
    "        sorted_peaks = [peaks[i] for i in sorted_peak_indices]\n",
    "\n",
    "        # Mark regions around each peak\n",
    "        for idx, peak_index in enumerate(sorted_peaks):\n",
    "            # Get the sample number corresponding to the peak index\n",
    "            peak_sample_no = sample_numbers[peak_index]\n",
    "            \n",
    "            # Define the range of indices for the region\n",
    "            if idx == 0:  # For the peak with the smallest sample number\n",
    "                start_index = max(peak_index - 10, 0)\n",
    "                end_index = min(peak_index + 6, len(sample_numbers))\n",
    "            else:  # For all other peaks\n",
    "                start_index = max(peak_index - 5, 0)\n",
    "                end_index = min(peak_index + 6, len(sample_numbers))\n",
    "            \n",
    "            # Extract sample numbers and values for the region\n",
    "            region_sample_no = sample_numbers[start_index:end_index]\n",
    "            region_values = samples[start_index:end_index]\n",
    "            \n",
    "            # Append the region to the list of regions\n",
    "            regions.append((region_sample_no, region_values))\n",
    "        \n",
    "        # Store the sample numbers and regions for the current file\n",
    "        sample_numbers_and_regions[file_name] = {\n",
    "            'sample_numbers': sample_numbers,\n",
    "            'regions': regions\n",
    "        }\n",
    "\n",
    "    return sample_numbers_and_regions\n",
    "\n",
    "# Call the function to extract sample numbers and regions for each file\n",
    "sample_numbers_and_regions = extract_sample_numbers_and_regions(table_data, precomputed_peaks)\n",
    "\n",
    "# Access and print the sample numbers and regions for each file\n",
    "for file_name, data in sample_numbers_and_regions.items():\n",
    "    print(f\"File: {file_name}\")\n",
    "    \n",
    "    # Print the extracted regions\n",
    "    print(\"Regions:\")\n",
    "    for idx, (region_sample_no, region_values) in enumerate(data['regions'], start=1):\n",
    "        print(f\"Region {idx} - Sample Numbers:\")\n",
    "        print(region_sample_no)\n",
    "        print(f\"Region {idx} - Sample Values:\")\n",
    "        print(region_values)\n",
    "    \n",
    "    print()  # Add a blank line for separation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d13dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_class_labels(table_data, sample_numbers_and_regions):\n",
    "    # Iterate over each file's data\n",
    "    for file_name, data in sample_numbers_and_regions.items():\n",
    "        regions = data['regions']\n",
    "        num_regions = len(regions)\n",
    "        \n",
    "        # Update class labels based on the number of regions\n",
    "        if num_regions == 3:\n",
    "            class_labels = [1, 3, 4]\n",
    "        elif num_regions == 2:\n",
    "            class_labels = [1, 4]\n",
    "        elif num_regions == 4:\n",
    "            class_labels = [1, 3, 3, 4]\n",
    "        else:\n",
    "            print(f\"Unsupported number of regions ({num_regions}) for {file_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Iterate over rows in table_data and update class labels\n",
    "        for row in table_data[file_name]:\n",
    "            sample_no = row[0]  # Extract sample number from the row\n",
    "            \n",
    "            # Find the region containing this sample number\n",
    "            for region_idx, (region_sample_no, _) in enumerate(regions):\n",
    "                if sample_no in region_sample_no:\n",
    "                    # Update the class label in the row \n",
    "                    if len(row) < 3:  # Check if the class label column exists\n",
    "                        row.append(class_labels[region_idx])  # Add a new class label column if it doesn't exist\n",
    "                    else:\n",
    "                        row[2] = class_labels[region_idx]  # Update the class label in the existing column\n",
    "                    break  # Stop searching once the region is found\n",
    "\n",
    "\n",
    "# Call the function to update the class labels in table_data\n",
    "update_class_labels(table_data, sample_numbers_and_regions)\n",
    "\n",
    "# Print the entire updated table_data with all columns\n",
    "for file_name, table_rows in table_data.items():\n",
    "    print(f\"File: {file_name}\")\n",
    "    print(\"Sample_no\\tSamples\\tClass_Label\")\n",
    "    for row in table_rows:\n",
    "        print(\"\\t\".join(map(str, row)))  # Print each row with tab-separated columns\n",
    "    print()  # Print a blank line after each file's data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_class_labels_in_table(table_data):\n",
    "    for file_name, table_rows in table_data.items():\n",
    "        print(f\"Updating Class_Labels for {file_name}:\")\n",
    "        \n",
    "        in_first_range = False\n",
    "        encountered_1 = False\n",
    "        encountered_3 = False\n",
    "\n",
    "        for row in table_rows:\n",
    "            class_label = row[2]  \n",
    "\n",
    "            if class_label == 1:\n",
    "                row[2] = 1\n",
    "                in_first_range = True\n",
    "                encountered_1 = True\n",
    "                encountered_3 = False\n",
    "            elif class_label == 3:\n",
    "                row[2] = 3\n",
    "                in_first_range = False\n",
    "                encountered_3 = True\n",
    "            elif class_label == 4:\n",
    "                row[2] = 4\n",
    "                in_first_range = False\n",
    "                encountered_1 = False\n",
    "                encountered_3 = False\n",
    "            elif in_first_range:\n",
    "                row[2] = 2  # Between 1 and 3\n",
    "            elif encountered_3:\n",
    "                row[2] = 2  # Between 3 and 4\n",
    "            else:\n",
    "                row[2] = 0  # Default to 0 before encountering 1\n",
    "\n",
    "    print(\"Class_Labels updated successfully.\")\n",
    "\n",
    "# Call the function to update Class_Labels in the table_data\n",
    "update_class_labels_in_table(table_data)\n",
    "\n",
    "# Print updated table_data\n",
    "for file_name, rows in table_data.items():\n",
    "    print(f\"Updated data for {file_name}:\")\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_columns_to_int(table_data):\n",
    "    # Iterate over each file's table data\n",
    "    for file_name, rows in table_data.items():\n",
    "        print(f\"Converting columns to int for {file_name}:\")\n",
    "        \n",
    "        # Convert rows to DataFrame\n",
    "        df = pd.DataFrame(rows, columns=['Sample_no', 'Samples', 'Class_Label'])\n",
    "        \n",
    "        # Convert 'Sample_no', 'Samples', 'Class_Label' columns to integers\n",
    "        df['Sample_no'] = pd.to_numeric(df['Sample_no'], errors='coerce')\n",
    "        df['Samples'] = pd.to_numeric(df['Samples'], errors='coerce')\n",
    "        df['Class_Label'] = pd.to_numeric(df['Class_Label'], errors='coerce')\n",
    "        \n",
    "        # Update the DataFrame in the table_data dictionary\n",
    "        table_data[file_name] = df\n",
    "    \n",
    "    return table_data\n",
    "\n",
    "\n",
    "# Convert columns to integers in each DataFrame within table_data\n",
    "table_data = convert_columns_to_int(table_data)\n",
    "\n",
    "\n",
    "for file_name, df in table_data.items():\n",
    "    print(f\"DataFrame for {file_name}:\")\n",
    "    print(df)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_with_class_labels(df):\n",
    "    # Create figure and axis\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "    # Plot Samples on primary y-axis\n",
    "    ax1.plot(df['Sample_no'], df['Samples'], color='b', linewidth=1.75)\n",
    "    ax1.set_xlabel('Sample_no')\n",
    "    ax1.set_ylabel('Samples', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "\n",
    "    # Create secondary y-axis for Class_Label\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(df['Sample_no'], df['Class_Label'], color='r', linewidth=1.75)\n",
    "    ax2.set_ylabel('Class_Label', color='r')\n",
    "    ax2.tick_params('y', colors='r')\n",
    "    ax2.set_yticks(range(int(df['Class_Label'].min()), int(df['Class_Label'].max()) + 1))\n",
    "\n",
    "    # Remove grid from y-axis\n",
    "    ax1.grid(axis='y', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    ax2.grid(False)\n",
    "\n",
    "    plt.title('Labelled Classes of the Samples')\n",
    "    plt.show()\n",
    "\n",
    "# Iterate over each file's table data and plot the data with class labels\n",
    "for file_name, df in table_data.items():\n",
    "    print(f\"Plotting data with class labels for {file_name}:\")\n",
    "    plot_data_with_class_labels(df)\n",
    "    print()  # a blank line for separation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78386f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f82f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def process_files_in_folder(folder_path, table_data):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No files found in '{folder_path}'.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(files)} files in '{folder_path}': {files}\")  # Debugging statement\n",
    "    \n",
    "    file_count = 0\n",
    "    \n",
    "    for file_name in files:\n",
    "        print(f\"Reading file: {file_name}\")  # Debugging statement\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            # Initialize variables to store extracted values\n",
    "            sample_length = None\n",
    "            point = None\n",
    "            x_cor, y_cor, z_cor = None, None, None  # Initialize variables for coordinates\n",
    "            \n",
    "            # Regular expression pattern to match floating-point numbers\n",
    "            pattern = r\"[-+]?\\d*\\.\\d+|\\d+\"\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    file_contents = file.readlines()\n",
    "                    \n",
    "                    print(f\"File contents length: {len(file_contents)}\")  # Debugging statement\n",
    "                    \n",
    "                    # Extract coordinates (x, y, z) from the first line (Point)\n",
    "                    if len(file_contents) >= 1:\n",
    "                        point_match = re.findall(pattern, file_contents[0])\n",
    "                        if len(point_match) >= 3:\n",
    "                            x_cor = float(point_match[0])\n",
    "                            y_cor = float(point_match[1])\n",
    "                            z_cor = float(point_match[2])\n",
    "                        print(f\"Coordinates extracted: x={x_cor}, y={y_cor}, z={z_cor}\")  # Debugging statement\n",
    "                    \n",
    "                    # Check if the file has at least 7 lines for sample length and point\n",
    "                    if len(file_contents) >= 7:\n",
    "                        sample_length_match = re.findall(pattern, file_contents[5])\n",
    "                        point_match = re.findall(pattern, file_contents[6])\n",
    "                        \n",
    "                        # Convert the matched values to floats\n",
    "                        if sample_length_match:\n",
    "                            sample_length = float(sample_length_match[0])\n",
    "                        if point_match:\n",
    "                            point = float(point_match[0])\n",
    "                        print(f\"Sample Length: {sample_length}, Point: {point}\")  # Debugging statement\n",
    "                            \n",
    "                        # Check if the file exists in table_data\n",
    "                        if file_name in table_data:\n",
    "                            df = table_data[file_name]\n",
    "                            print(f\"Updating DataFrame for {file_name}\")  # Debugging statement\n",
    "                            \n",
    "                            # Update DataFrame with extracted values\n",
    "                            df['x_cor'] = x_cor\n",
    "                            df['y_cor'] = y_cor\n",
    "                            df['z_cor'] = z_cor\n",
    "                            df['Sample_Length'] = sample_length\n",
    "                            df['Point'] = point\n",
    "                            df['Returning_Point'] = int(point / sample_length) if sample_length else None\n",
    "                            \n",
    "                            file_count += 1\n",
    "                            print(f\"Processed file: {file_name}\")\n",
    "                        else:\n",
    "                            print(f\"File {file_name} not found in table_data. Available keys: {list(table_data.keys())}\")  # Debugging statement\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing '{file_name}': {e}\")\n",
    "        else:\n",
    "            print(f\"'{file_name}' is not a file.\")\n",
    "    \n",
    "    print(f\"Processed {file_count} files.\")\n",
    "\n",
    "    folder_path = 'Text Files/'\n",
    "process_files_in_folder(folder_path, table_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cdd98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def assign_final_classes(table_data):\n",
    "    \n",
    "    for file_name, df in table_data.items():\n",
    "        returning_point = df['Returning_Point'].iloc[0]  \n",
    "        \n",
    "        # Find the Sample_no corresponding to the Returning_Point\n",
    "        sample_no_with_point = df.loc[df['Sample_no'] == returning_point, 'Sample_no'].values\n",
    "        \n",
    "        if len(sample_no_with_point) > 0:\n",
    "            # Get the corresponding Class_Label for the Sample_no\n",
    "            final_class = df.loc[df['Sample_no'] == sample_no_with_point[0], 'Class_Label'].iloc[0]\n",
    "            \n",
    "            # Assign Final_Class to the DataFrame\n",
    "            df['Final_Class'] = final_class\n",
    "        else:\n",
    "            # If no corresponding Sample_no found, assign NaN or handle accordingly\n",
    "            df['Final_Class'] = None\n",
    "    \n",
    "    print(\"Final classes assigned successfully.\")\n",
    "\n",
    "def print_final_table(table_data):\n",
    "    # Print the final table for each file\n",
    "    for file_name, df in table_data.items():\n",
    "        print(f\"File: {file_name}\")\n",
    "        print(df)  \n",
    "        print()  \n",
    "\n",
    "\n",
    "assign_final_classes(table_data)\n",
    "\n",
    "#the final table with the assigned final classes\n",
    "print_final_table(table_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a07ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_final_data(df, file_name):\n",
    "    # Create a figure and axis\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "    \n",
    "    # Plot Samples on primary y-axis\n",
    "    ax1.plot(df['Sample_no'], df['Samples'], color='b', linewidth=1.75, label='Samples')\n",
    "    ax1.set_xlabel('Sample_no')\n",
    "    ax1.set_ylabel('Samples', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "\n",
    "    # Create secondary y-axis for Class_Label\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(df['Sample_no'], df['Class_Label'], color='r', linewidth=1.75, label='Class_Label')\n",
    "    ax2.set_ylabel('Class_Label', color='r')\n",
    "    ax2.tick_params('y', colors='r')\n",
    "    ax2.set_yticks(range(int(df['Class_Label'].min()), int(df['Class_Label'].max()) + 1))\n",
    "\n",
    "    # Mark the Returning Point\n",
    "    returning_point = df['Returning_Point'].iloc[0]  # Returning_Point is the same for all lines in the file\n",
    "    ax1.axvline(x=returning_point, color='g', linestyle='--', linewidth=1.5, label='Returning Point')\n",
    "    \n",
    "    # Add legends to the plot\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    ax1.grid(axis='y', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    ax2.grid(False)\n",
    "    \n",
    "   \n",
    "    plt.title(f'{file_name} - Samples, Class Label, and Returning Point')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_final_data(table_data):\n",
    "    # Iterate over each file's data and plot the final data\n",
    "    for file_name, df in table_data.items():\n",
    "        plot_final_data(df, file_name)\n",
    "\n",
    "\n",
    "plot_all_final_data(table_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b13781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def save_dataframes_as_csv(table_data, output_folder):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Dictionary to store file paths grouped by class label\n",
    "    class_file_paths = defaultdict(list)\n",
    "    \n",
    "    for file_name, df in table_data.items():\n",
    "        # Extract Final_Class value\n",
    "        final_class = df['Final_Class'].iloc[0]\n",
    "        \n",
    "        # Create new file name using the original file name and the final class label\n",
    "        new_file_name = f\"class_label_{final_class}_{file_name.split('.')[0]}.csv\"\n",
    "        output_path = os.path.join(output_folder, new_file_name)\n",
    "        \n",
    "        # Save the DataFrame as a CSV file with the new name\n",
    "        df.to_csv(output_path, index=False)\n",
    "        \n",
    "        # Store the file path in the dictionary under the corresponding class label\n",
    "        class_file_paths[final_class].append(output_path)\n",
    "    \n",
    "    # Print the saved file paths sorted by class label\n",
    "    for class_label in sorted(class_file_paths.keys()):\n",
    "        print(f\"Class_label_{class_label}:\")\n",
    "        for path in class_file_paths[class_label]:\n",
    "            print(f\"Saved: {path}\")\n",
    "        print()  # Blank line for separation between class labels\n",
    "\n",
    "# Save each DataFrame as a CSV with the new naming convention\n",
    "output_folder = 'New_Data_Processed/'\n",
    "save_dataframes_as_csv(table_data, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
